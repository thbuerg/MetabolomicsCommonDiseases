import os
import torch
import pandas as pd

from tqdm import tqdm
from pathlib import Path
from pytorch_lightning.callbacks.base import Callback


class WriteCheckpointLogs(Callback):
    """
    Write final logs to neptune.
    """
    def on_keyboard_interrupt(self, trainer, pl_module, device='cuda:0'):
        self.on_epoch_end(trainer, pl_module)

    def on_epoch_end(self, trainer, pl_module):
        if isinstance(trainer.logger, list):
            logger = trainer.logger[0]
        else:
            logger = trainer.logger
        if torch.is_tensor(trainer.checkpoint_callback.best_model_score):
            logger.run["checkpoint_metric"] = trainer.checkpoint_callback.monitor
            logger.run["checkpoint_value"] = str(trainer.checkpoint_callback.best_model_score.item())
            logger.run["checkpoint_path"] = trainer.checkpoint_callback.best_model_path


class WritePredictionsDataFrame(Callback):
    """
    Write Predictions generated by `predict_dataset` or `predict_dataset_with_uncertainty` that return pd.DataFrames.
    """
    def __init__(self, write_calibrated_predictions=True, **kwargs):
        super().__init__()
        self.write_calibrated_predictions = write_calibrated_predictions

    def on_keyboard_interrupt(self, trainer, module, device='cuda:0'):
        self.on_fit_end(trainer, module, device)

    def on_fit_end(self, trainer, module, device='cuda:0'): # how to set inference device better? adaptive to train device?
        ckpt = torch.load(trainer.checkpoint_callback.best_model_path)
        module.load_state_dict(ckpt['state_dict'])
        module.eval()
        module.to(device)

        time_max = 26 # effective real time max is time_max-2 -> 25 years
        times = [e for e in range(1, time_max, 1)]
        if self.write_calibrated_predictions:
            module.fit_isotonic_regressor(trainer.datamodule.train_ds, times, 100000)

        # write the predictions.csv
        predictions = {}
        for ds_idx, (ds, ds_name) in enumerate(tqdm([(trainer.datamodule.train_ds, 'train'),
                                                     (trainer.datamodule.valid_ds, 'valid'),
                                                     (trainer.datamodule.test_ds, 'test')])):
            if self.write_calibrated_predictions:
                 predictions[ds_name] = module.predict_dataset_calibrated(ds, times)
            else:
                predictions[ds_name] = module.predict_dataset(ds, times)
            predictions[ds_name]['eid'] = ds.datasets[0].eid_map.index.values
            predictions[ds_name]["split"] = ds_name
        predictions_df = pd.concat([*predictions.values()]).reset_index(drop=True)
        predictions_df["partition"] = trainer.datamodule.cv_partition
        predictions_df["module"] = type(module).__name__
        try:
            predictions_df["net"] = type(module.net).__name__
        except AttributeError:
            pass
        predictions_df["datamodule"] = type(trainer.datamodule).__name__
        predictions_df["event_names"] = str(trainer.datamodule.event)
        predictions_df["feature_names"] = str(trainer.datamodule.features)

        self.write_and_log(trainer, predictions_df)

    def write_and_log(self, trainer, predictions_df):
        # write the predictions.csv
        outdir = os.path.join(Path(trainer.checkpoint_callback.dirpath).parent, "predictions")
        if not os.path.exists(outdir):
            os.mkdir(outdir)
        predictions_df.to_feather(os.path.join(outdir, "predictions.feather"))
        predictions_df.to_csv(os.path.join(outdir, "predictions.csv"))

        if isinstance(trainer.logger, list):
            trainer.logger[0].run["prediction_available"] = "TRUE"
            trainer.logger[0].run["prediction_path"] = os.path.join(outdir, "predictions.feather")
        else:
            trainer.logger.run["prediction_available"] = "TRUE"
            trainer.logger.run["prediction_path"] = os.path.join(outdir, "predictions.feather")
